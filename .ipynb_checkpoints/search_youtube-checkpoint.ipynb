{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# suzanita+lucifer; suzanita+kaskata; луцифер+буда; сузанита+луцифер; amulet+biz;\n",
    "\n",
    "# Include the search term. Multiple terms should be separated with a \"+\" (no spaces)\n",
    "textToSearch = \"сузанита+луцифер\"\n",
    "\n",
    "# Initialize empty lists for the data I'll be collecting - videos' links, titles, uploader, and number of days since upload\n",
    "video_link = []\n",
    "video_title = []\n",
    "video_user = []\n",
    "uploaded_since = []\n",
    "video_views = []\n",
    "search_term = []\n",
    "\n",
    "\n",
    "## Search loop\n",
    "# This should eventually become a loop downloading the first 5 pages which YouTube returns \n",
    "for page_num in range(1, 11):\n",
    "\n",
    "    # Create a search query and download the HTML code \n",
    "    query = urllib.quote(textToSearch)\n",
    "    url = \"https://www.youtube.com/results?search_query=\" + query + \"&page=\" + str(page_num)\n",
    "    response = urllib2.urlopen(url)\n",
    "    html = response.read().decode('utf-8')\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    # Print the whole HTML code from the BeautifulSoup object\n",
    "    # print soup.prettify()[0:1000]\n",
    "\n",
    "    ## List the links to the videos and their titles\n",
    "    for vids in soup.find_all(attrs = {\"class\": \"yt-uix-tile-link\"}):\n",
    "        video_link.append(\"https://www.youtube.com\" + vids[\"href\"])\n",
    "        video_title.append(vids[\"title\"])\n",
    "\n",
    "    ## Obtain the username and channel\n",
    "    for user in soup.find_all(\"a\", attrs = {\"class\": \"g-hovercard\"}):\n",
    "        video_user.append(\"https://www.youtube.com\" + user[\"href\"])\n",
    "\n",
    "    ## Get the number of days ago a video was uploaded\n",
    "    for stats in soup.find_all(\"ul\", attrs = {\"class\": \"yt-lockup-meta-info\"}):\n",
    "        try:\n",
    "            uploaded_since.append(stats.li.get_text())\n",
    "            video_views.append(stats.li.next_sibling.get_text())\n",
    "        except:\n",
    "            uploaded_since.append(\"No Data\")\n",
    "            video_views.append(\"No Data\")\n",
    "\n",
    "\n",
    "# Add the search term that was used\n",
    "search_term = [textToSearch] * len(video_link)\n",
    "\n",
    "\n",
    "## Create a dataframe with the video links, titles, username and number of views\n",
    "final_combined_df = pd.DataFrame(list(zip(video_link, video_title, video_views, search_term)),\n",
    "                                 columns = [\"video_link\", \"video_title\", \"video_views\", \"search_term\"])\n",
    "final_combined_df.head(10)\n",
    "\n",
    "## Write to a CSV on Google Drive\n",
    "writer_excel = pd.ExcelWriter(\"C:/Users/bre49823/Google Drive/VideoSearch/videos_links_searchterm_\" + textToSearch + \".xlsx\")\n",
    "final_combined_df.to_excel(writer_excel, 'Sheet1')\n",
    "writer_excel.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning the search...\n",
      "The program will collect the information from the first 150 videos returned in the search\n",
      "The total number of videos found on YouTube for the search term луцифер+буда are: 2625\n",
      "Extracting content from page: 1\n",
      "The next page token is: CDIQAA\n",
      "Extracting content from page: 2\n",
      "The next page token is: CGQQAA\n",
      "Extracting content from page: 3\n",
      "The next page token is: CJYBEAA\n",
      "\n",
      "Stack the information about videos in a Pandas dataframe\n",
      "                                    video_link  \\\n",
      "0  https://www.youtube.com/watch?v=79lSgG012xg   \n",
      "1  https://www.youtube.com/watch?v=h9MFT4J1-jQ   \n",
      "2  https://www.youtube.com/watch?v=tkJqWmY6I2Q   \n",
      "3  https://www.youtube.com/watch?v=C1stWeuoPRM   \n",
      "4  https://www.youtube.com/watch?v=inRNp5En-yw   \n",
      "5  https://www.youtube.com/watch?v=N3_BGW0P4V0   \n",
      "6  https://www.youtube.com/watch?v=ouxJ1KiQj8M   \n",
      "7  https://www.youtube.com/watch?v=jykzPNt5rMo   \n",
      "8  https://www.youtube.com/watch?v=PYjBZA4tBDE   \n",
      "9  https://www.youtube.com/watch?v=x44GmR3yoa8   \n",
      "\n",
      "                                         video_title           video_user  \\\n",
      "0                         ОБЛАДАН ОТ ЛУЦИФЕР И БУДА!             Bossaide   \n",
      "1                                     Луцифер и Буда       Nicole's Edits   \n",
      "2  Луцифер и Буда - Suzanitta (Сузанита) ft. Зипо...  Zipo_Slash_Official   \n",
      "3  БАБА РЕАГИРА НА ПЕСЕНТА НА СУЗАНИТА - ЛУЦИФЕР ...           Persi Army   \n",
      "4                  ИМАЛО ЕДНО ВРЕМЕ (ЛУЦИФЕР И БУДА)          Ghost Front   \n",
      "5   Стаята Еп. 3 - Луцифер, Буда.. Неприятна работа.               Toshey   \n",
      "6                      ОБЛАДАНА ОТ ЛУЦИФЕР И БУДА???               Boga42   \n",
      "7                Изтриха Луцифер и Буда !! ЗАЩО ?!?!         Kristiyan X.   \n",
      "8                      Обладан съм от Луцифер и Буда         Iliyan Radev   \n",
      "9                      Реакция на ,,Луцифер и Буда''        Петьо Mаринов   \n",
      "\n",
      "                                  video_user_channel video_publish_date  \\\n",
      "0  https://www.youtube.com/channel/UC-kaaWNHt2dSN...         2017-07-19   \n",
      "1  https://www.youtube.com/channel/UCvg19vhYzWCZK...         2017-08-09   \n",
      "2  https://www.youtube.com/channel/UCRw0GahNNJ7s3...         2017-07-24   \n",
      "3  https://www.youtube.com/channel/UCCIoM3SUmo9yq...         2017-07-25   \n",
      "4  https://www.youtube.com/channel/UC06KvP9JrPTQT...         2017-08-09   \n",
      "5  https://www.youtube.com/channel/UCYrWVWA5udLD7...         2017-07-23   \n",
      "6  https://www.youtube.com/channel/UClpZJdXWfnzlX...         2017-07-22   \n",
      "7  https://www.youtube.com/channel/UCfQLMjU9MKeBY...         2017-08-08   \n",
      "8  https://www.youtube.com/channel/UCU7kno_GQu6f6...         2017-07-23   \n",
      "9  https://www.youtube.com/channel/UCQZyCSlqZTqMv...         2017-07-19   \n",
      "\n",
      "  search_term_used  \n",
      "0     луцифер+буда  \n",
      "1     луцифер+буда  \n",
      "2     луцифер+буда  \n",
      "3     луцифер+буда  \n",
      "4     луцифер+буда  \n",
      "5     луцифер+буда  \n",
      "6     луцифер+буда  \n",
      "7     луцифер+буда  \n",
      "8     луцифер+буда  \n",
      "9     луцифер+буда  \n",
      "\n",
      "Write file to Excel on Google Drive\n",
      " The location is: C:/Users/bre49823/Google Drive/VideoSearch/videos_links_searchterm_луцифер+буда.xlsx\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xd0 in position 7: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-497-0210d8bbc261>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[0mwriter_excel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_output_location\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/videos_links_searchterm_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msearch_term_save\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[0mfinal_combined_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter_excel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sheet1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m \u001b[0mwriter_excel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\bre49823\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas\\io\\excel.pyc\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1549\u001b[0m         \"\"\"\n\u001b[0;32m   1550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1551\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m     def write_cells(self, cells, sheet_name=None, startrow=0, startcol=0,\n",
      "\u001b[1;32mC:\\Users\\bre49823\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\xlsxwriter\\workbook.pyc\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileclosed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileclosed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bre49823\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\xlsxwriter\\workbook.pyc\u001b[0m in \u001b[0;36m_store_workbook\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mpackager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_tmpdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[0mpackager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_in_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_memory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m         \u001b[0mxml_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpackager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_package\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m         \u001b[1;31m# Free up the Packager object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bre49823\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\xlsxwriter\\packager.pyc\u001b[0m in \u001b[0;36m_create_package\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_comment_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_table_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_shared_strings_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_app_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_core_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bre49823\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\xlsxwriter\\packager.pyc\u001b[0m in \u001b[0;36m_write_shared_strings_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[0msst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_xml_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'xl/sharedStrings.xml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[0msst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assemble_xml_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_write_app_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bre49823\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\xlsxwriter\\sharedstrings.pyc\u001b[0m in \u001b[0;36m_assemble_xml_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;31m# Write the sst strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_sst_strings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# Close the sst tag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bre49823\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\xlsxwriter\\sharedstrings.pyc\u001b[0m in \u001b[0;36m_write_sst_strings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_strings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_si\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_write_si\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bre49823\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\xlsxwriter\\sharedstrings.pyc\u001b[0m in \u001b[0;36m_write_si\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xml_rich_si_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xml_si_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bre49823\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\xlsxwriter\\xmlwriter.pyc\u001b[0m in \u001b[0;36m_xml_si_element\u001b[1;34m(self, string, attributes)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mstring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_escape_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"<si><t%s>%s</t></si>\"\"\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_xml_rich_si_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bre49823\\AppData\\Local\\Continuum\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwritelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bre49823\\AppData\\Local\\Continuum\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, object)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \"\"\" Writes the object's contents encoded to self.stream.\n\u001b[0;32m    368\u001b[0m         \"\"\"\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xd0 in position 7: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Use the following search terms: suzanita+lucifer; suzanita+kaskata; луцифер+буда; сузанита+луцифер; amulet+biz;\n",
    "\n",
    "\n",
    "# Define the parameters\n",
    "search_term = \"луцифер+буда\"\n",
    "search_term_save = \"lucifer+buda_bg\"\n",
    "\n",
    "api_key = \"AIzaSyDHXROE2Qt0NglgCmTnO8Y8cMikF5mD-m4\"\n",
    "\n",
    "search_pages = 3\n",
    "search_results_per_page = 50\n",
    "final_output_location = \"C:/Users/bre49823/Google Drive/VideoSearch\"\n",
    "\n",
    "\n",
    "# Initialize empty lists for the data I'll be collecting - videos' links, titles, uploader, channel, and date uploaded on\n",
    "video_link = []\n",
    "video_title = []\n",
    "video_user = []\n",
    "video_user_channel = []\n",
    "video_publish_date = []\n",
    "search_term_used = []\n",
    "\n",
    "\n",
    "# Create an empty token value for the first page - Each search page returned has a token\n",
    "# To go to the next page with results we need to add the token value to the end of the url\n",
    "# The token value will be updated from the JSON file which is returned in the API call\n",
    "next_page_token = \"\"\n",
    "\n",
    "print (\"Beginning the search...\")\n",
    "time.sleep(1)\n",
    "\n",
    "# Loop through the first n pages of search results\n",
    "for page_results in range(1, (search_pages + 1)):\n",
    "\n",
    "    # API call and JSON response\n",
    "    search_url = (\"https://www.googleapis.com/youtube/v3/search?part=snippet&maxResults=\" + str(search_results_per_page) + \"&q=\" + search_term + \"&key=\" + api_key + \"&pageToken=\" + next_page_token)\n",
    "    api_response = requests.get(url = search_url)\n",
    "    json_data = json.loads(api_response.text)\n",
    "    \n",
    "    if page_results == 1:\n",
    "        print (\"The program will collect the information from the first \" + str(search_pages * search_results_per_page) + \" videos returned in the search\")\n",
    "        time.sleep(1)\n",
    "        print (\"The total number of videos found on YouTube for the search term \" + search_term + \" are: \" + str(json_data['pageInfo']['totalResults']))\n",
    "\n",
    "    # Update the token for the next page with search results\n",
    "    next_page_token = str(json_data['nextPageToken'])\n",
    "\n",
    "    print (\"Extracting content from page: \" + str(page_results))\n",
    "    print (\"The next page token is: \" + str(next_page_token))\n",
    "    \n",
    "    # Loop through all the search results returned in the API\n",
    "    for videos in range(1, len(json_data['items'])):\n",
    "        \n",
    "        # Get the link to video\n",
    "        video_link.append(\"https://www.youtube.com/watch?v=\" + json_data['items'][videos]['id'].values()[1])\n",
    "\n",
    "        # Get title of video\n",
    "        video_title.append(json_data['items'][videos]['snippet']['title'])\n",
    "\n",
    "        # Get the user name/channel name from which a video was uploaded\n",
    "        video_user.append(json_data['items'][videos]['snippet']['channelTitle'])\n",
    "\n",
    "        # Get link to the channel\n",
    "        video_user_channel.append(\"https://www.youtube.com/channel/\" + json_data['items'][videos]['snippet']['channelId'])\n",
    "    \n",
    "        # Date of video upload. The extract date is a string, from which the data is extracted\n",
    "        # Example from here: https://stackoverflow.com/questions/37192942/extract-date-from-string-in-python\n",
    "        string_date = str(json_data['items'][videos]['snippet']['publishedAt'])\n",
    "        match = re.search(r'\\d{4}-\\d{2}-\\d{2}', string_date)\n",
    "        date = datetime.strptime(match.group(), '%Y-%m-%d').date()\n",
    "        video_publish_date.append(date)\n",
    "    \n",
    "    \n",
    "# Add the search term that was used\n",
    "search_term_used = [search_term] * len(video_link)\n",
    "\n",
    "## Create a dataframe with the video links, titles, username and number of views\n",
    "print (\"\\nStack the information about videos in a Pandas dataframe\")\n",
    "time.sleep(1)\n",
    "\n",
    "final_combined_df = pd.DataFrame(list(zip(video_link, video_title, video_user, video_user_channel, video_publish_date, search_term_used)),\n",
    "                                 columns = ['video_link', 'video_title', 'video_user', 'video_user_channel', 'video_publish_date', 'search_term_used'])\n",
    "print (final_combined_df.head(10))\n",
    "\n",
    "\n",
    "## Write to a CSV on Google Drive\n",
    "print (\"\\nWrite file to Excel on Google Drive\\n The location is: \"  + final_output_location + \"/videos_links_searchterm_\" + search_term_save + \".xlsx\")\n",
    "\n",
    "writer_excel = pd.ExcelWriter(final_output_location + \"/videos_links_searchterm_\" + search_term_save + \".xlsx\")\n",
    "final_combined_df.to_excel(writer_excel, 'Sheet1')\n",
    "writer_excel.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading page: 1\n",
      "https://www.googleapis.com/youtube/v3/search?part=snippet&maxResults=50&q=&key=AIzaSyDHXROE2Qt0NglgCmTnO8Y8cMikF5mD-m4&pageToken=\n",
      "Downloading page: 2\n",
      "https://www.googleapis.com/youtube/v3/search?part=snippet&maxResults=50&q=&key=AIzaSyDHXROE2Qt0NglgCmTnO8Y8cMikF5mD-m4&pageToken=CDIQAA\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Use the following search terms: suzanita+lucifer; suzanita+kaskata; луцифер+буда; сузанита+луцифер; amulet+biz;\n",
    "\n",
    "# Define the parameters\n",
    "api_key = \"AIzaSyDHXROE2Qt0NglgCmTnO8Y8cMikF5mD-m4\"\n",
    "search_term = \"луцифер+буда\"\n",
    "search_pages = 2\n",
    "\n",
    "next_page_token = \"\"\n",
    "\n",
    "# Loop through the first n pages of search results\n",
    "for page_results in range(1, (search_pages + 1)):\n",
    "\n",
    "    print (\"Downloading page: \" + str(page_results))\n",
    "    # API call and JSON response\n",
    "    search_url = unicode((\"https://www.googleapis.com/youtube/v3/search?part=snippet&maxResults=50&q=луцифер&key=AIzaSyDHXROE2Qt0NglgCmTnO8Y8cMikF5mD-m4&pageToken=\" + next_page_token), errors = 'ignore')\n",
    "    api_response = requests.get(url = search_url)\n",
    "    json_data = json.loads(api_response.text)\n",
    "    \n",
    "    # Update the token for the next page with search results\n",
    "    next_page_token = str(json_data['nextPageToken'])\n",
    "    \n",
    "    print (search_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CDIQAA'"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_page_token = json_data['nextPageToken']\n",
    "str(next_page_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
