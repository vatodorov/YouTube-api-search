{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Program to search YouTube using its API\n",
    "(by Valentin Todorov - 11/28/2017)\n",
    "<br>\n",
    "This program is used for checking if the videos I asked YouTube to remove have actually been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import the packages I need\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "# This code would be faster if I pass a list with all the video IDs in the API call\n",
    "# Note that I can pass a list of videos separated by \"%2C+\". And the JSON returns information for all of them\n",
    "# API call with multiple videos:\n",
    "#   https://www.googleapis.com/youtube/v3/videos?part=snippet%2CcontentDetails%2Cstatistics&id=J30UOKAD4jw%2C+egTZVzh8wtQ&key={YOUR_API_KEY}\n",
    "    \n",
    "    \n",
    "# Allocate values to variables\n",
    "api_key = \"AIzaSyDHXROE2Qt0NglgCmTnO8Y8cMikF5mD-m4\"\n",
    "final_output_location = \"/Users/valentin/Documents/VideoSearch\"\n",
    "api_url_prefix = \"https://www.googleapis.com/youtube/v3/videos?part=snippet%2CcontentDetails%2Cstatistics&id=\"\n",
    "\n",
    "# Read the XLS file with the links Bijan sent to YouTube\n",
    "videos_sent = pd.read_excel(final_output_location + \"/videos_links_final_send.xlsx\")\n",
    "vids_not_removed = videos_sent[\"video_removed\"].tolist()\n",
    "vids_links = videos_sent[\"video_link\"]\n",
    "\n",
    "today_date = time.strftime(\"%d/%m/%Y\")\n",
    "video_removed = \"VIDEO HAS BEEN REMOVED\"\n",
    "\n",
    "\n",
    "# Create empty lists for number of views and the video links\n",
    "video_views = []\n",
    "video_link = []\n",
    "#video_likes = []\n",
    "#video_dislikes = []\n",
    "\n",
    "\n",
    "# Loop through all videos in the file I sent to Bijan\n",
    "for i in range(len(vids_links)):\n",
    "    \n",
    "    # This condition is True if a video is still available on YouTube\n",
    "    if vids_not_removed[i] == \"VIDEO IS STILL AVAILABLE\":\n",
    "        \n",
    "        video_link.append(vids_links[i])\n",
    "        print i, vids_links[i]\n",
    "\n",
    "        # Get the video ID, create the search url for the API and download the JSON file which contains the needed information\n",
    "        videoid_test = vids_links[i].split(\"watch?v=\")[1]\n",
    "        search_url = (api_url_prefix + videoid_test + \"&key=\" + api_key)\n",
    "        api_response = requests.get(url = search_url)\n",
    "        json_data = json.loads(api_response.text)\n",
    "    \n",
    "        # Get the number of views\n",
    "        try:\n",
    "            video_views.append(json_data[\"items\"][0][\"statistics\"][\"viewCount\"])\n",
    "            \n",
    "        except:\n",
    "            video_views.append(video_removed)\n",
    "\n",
    "        # Count of likes\n",
    "        #video_likes.append(json_data['items'][0]['statistics']['likeCount'])\n",
    "\n",
    "        # Count of dislikes\n",
    "        #video_dislikes.append(json_data['items'][0]['statistics']['dislikeCount'])\n",
    "\n",
    "\n",
    "# Combine the lists into a dataframe        \n",
    "## Create a dataframe with the video links, titles, username and number of views\n",
    "print (\"\\nStack the extracted data in a Pandas dataframe\")\n",
    "time.sleep(1)\n",
    "\n",
    "# Create a field with today's date and add it to the data frame\n",
    "latest_date = [today_date] * len(video_link)\n",
    "\n",
    "video_stats_df = pd.DataFrame(list(zip(video_link, video_views, latest_date)),\n",
    "                              columns = [\"video_link\", \"video_views\", \"latest_date\"])\n",
    "\n",
    "## Write the file with the tests to Google Drive\n",
    "print (\"\\nWrite the file with the video stats to Excel on Google Drive\\n The location is: \" + final_output_location + \"/video_stats.xlsx\")\n",
    "\n",
    "write_video_stats_excel = pd.ExcelWriter(final_output_location + \"/video_stats.xlsx\")\n",
    "video_stats_df.to_excel(write_video_stats_excel, \"Sheet1\")\n",
    "write_video_stats_excel.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
