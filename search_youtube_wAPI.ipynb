{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Program to search YouTube using its API\n",
    "###### (by Valentin Todorov - 08/28/2017)\n",
    "This program was developed to scrub all videos from Suzanita & Kaskata in which \"Allahumma Ya Subuhun\" can be heard in the background.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning the search...\n",
      "The program will collect the information from the first 100 videos returned in the search\n",
      "The total number of videos found on YouTube for the search term suzanita+lucifer are: 1530\n",
      "Extracting content from page: 1\n",
      "The next page token is: CDIQAA\n",
      "Extracting content from page: 2\n",
      "The next page token is: CGQQAA\n",
      "\n",
      "Stack the information about videos in a Pandas dataframe\n",
      "\n",
      "Write file to Excel on Google Drive\n",
      " The location is: C:/Users/bre49823/Desktop/Misc/videos_links_searchterm_suzanita+lucifer.xlsx\n",
      "\n",
      "Complete!\n",
      "File successfully written to Excel for search term: suzanita+lucifer\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries that will be used in the program\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "## Search terms: suzanita+lucifer; suzanita+kaskata; луцифер+буда; сузанита+луцифер; amulet+biz;\n",
    "\n",
    "\n",
    "# Define the parameters\n",
    "# For search terms in Bulgarian only -->>  (1) In \"search_term\" write the search in Bulgarian, and (2) in \"search_term_save\" write the search in English\n",
    "search_term = \"suzanita+lucifer\"\n",
    "search_term_save = \"suzanita+lucifer\" # + \"_inBulgarian\"     #-->> uncomment only when using Bulgarian search terms <<--#\n",
    "\n",
    "# My API key from YouTube\n",
    "api_key = \"AIzaSyDHXROE2Qt0NglgCmTnO8Y8cMikF5mD-m4\"\n",
    "\n",
    "# Set the parameters for the number of search pages to return, the number of records per search page and the location of the final Excel file\n",
    "search_pages = 2\n",
    "search_results_per_page = 50\n",
    "final_output_location = \"C:/Users/bre49823/Google Drive/VideoSearch\"\n",
    "\n",
    "\n",
    "# Initialize empty lists for the data I'll be collecting - videos' links, titles, uploader, channel, and date uploaded on\n",
    "video_link = []\n",
    "video_title = []\n",
    "video_user = []\n",
    "video_user_channel = []\n",
    "video_publish_date = []\n",
    "search_term_used = []\n",
    "\n",
    "\n",
    "# Create an empty token value for the first page - Each search page returned has a token\n",
    "# To go to the next page with results we need to add the token value to the end of the url\n",
    "# The token value will be updated from the JSON file which is returned in the API call\n",
    "next_page_token = \"\"\n",
    "\n",
    "print (\"Beginning the search...\")\n",
    "time.sleep(1)\n",
    "\n",
    "# Loop through the first n pages of search results\n",
    "for page_results in range(1, (search_pages + 1)):\n",
    "\n",
    "    # API call and JSON response\n",
    "    search_url = (\"https://www.googleapis.com/youtube/v3/search?part=snippet&maxResults=\" + str(search_results_per_page) + \"&q=\" + search_term + \"&key=\" + api_key + \"&pageToken=\" + next_page_token)\n",
    "    api_response = requests.get(url = search_url)\n",
    "    json_data = json.loads(api_response.text)\n",
    "    \n",
    "    if page_results == 1:\n",
    "        print (\"The program will collect the information from the first \" + str(search_pages * search_results_per_page) + \" videos returned in the search\")\n",
    "        time.sleep(1)\n",
    "        print (\"The total number of videos found on YouTube for the search term \" + search_term + \" are: \" + str(json_data['pageInfo']['totalResults']))\n",
    "\n",
    "    # Update the token for the next page with search results\n",
    "    next_page_token = str(json_data['nextPageToken'])\n",
    "\n",
    "    print (\"Extracting content from page: \" + str(page_results))\n",
    "    print (\"The next page token is: \" + str(next_page_token))\n",
    "    \n",
    "    # Loop through all the search results returned in the API\n",
    "    for videos in range(1, len(json_data['items'])):\n",
    "        \n",
    "        # Get the link to video\n",
    "        video_link.append(\"https://www.youtube.com/watch?v=\" + json_data['items'][videos]['id'].values()[1])\n",
    "\n",
    "        # Get title of video\n",
    "        video_title.append(json_data['items'][videos]['snippet']['title'])\n",
    "\n",
    "        # Get the user name/channel name from which a video was uploaded\n",
    "        video_user.append(json_data['items'][videos]['snippet']['channelTitle'])\n",
    "\n",
    "        # Get link to the channel\n",
    "        video_user_channel.append(\"https://www.youtube.com/channel/\" + json_data['items'][videos]['snippet']['channelId'])\n",
    "   \n",
    "        # Date of video upload. The extract date is a string, from which the data is extracted\n",
    "        # Example from here: https://stackoverflow.com/questions/37192942/extract-date-from-string-in-python\n",
    "        string_date = str(json_data['items'][videos]['snippet']['publishedAt'])\n",
    "        match = re.search(r'\\d{4}-\\d{2}-\\d{2}', string_date)\n",
    "        date = datetime.strptime(match.group(), '%Y-%m-%d').date()\n",
    "        video_publish_date.append(date)\n",
    "\n",
    "\n",
    "# Add the search term that was used\n",
    "search_term_used = [search_term_save] * len(video_link)\n",
    "\n",
    "## Create a dataframe with the video links, titles, username and number of views\n",
    "print (\"\\nStack the information about videos in a Pandas dataframe\")\n",
    "time.sleep(1)\n",
    "\n",
    "final_combined_df = pd.DataFrame(list(zip(video_link, video_title, video_user, video_user_channel, video_publish_date, search_term_used)),\n",
    "                                 columns = ['video_link', 'video_title', 'video_user', 'video_user_channel', 'video_publish_date', 'search_term_used'])\n",
    "final_combined_df.head(10)\n",
    "\n",
    "\n",
    "############################################\n",
    "#######  Add functionalities\n",
    "############################################\n",
    "\n",
    "# Dedup the dataframe by video_link\n",
    "# YouTube returns the same video in the search results when using different search terms)\n",
    "\n",
    "\n",
    "\n",
    "# Remove rows where len(video_link) > 43. Playlists and channels have a url length greater than 43\n",
    "# These can also be removed through the API -> (json_data['items'][tt]['id'].values()[0] == \"youtube#video\")\n",
    "\n",
    "\n",
    "\n",
    "# Create a flag which videos to keep - use the logic I created in Excel\n",
    "# The videos with the flag are more likely to include Allahumma Ya Subuhun in the background\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Write to an Excel file on Google Drive\n",
    "print (\"\\nWrite file to Excel on Google Drive\\n The location is: \"  + final_output_location + \"/videos_links_searchterm_\" + search_term_save + \".xlsx\")\n",
    "\n",
    "writer_excel = pd.ExcelWriter(final_output_location + \"/videos_links_searchterm_\" + search_term_save + \".xlsx\")\n",
    "final_combined_df.to_excel(writer_excel, 'Sheet1')\n",
    "writer_excel.save()\n",
    "\n",
    "print (\"\\nComplete!\\nFile successfully written to Excel for search term: \" + search_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
